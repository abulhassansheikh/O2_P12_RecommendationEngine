{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O2_P12_RecommendationEngine_RnD_DataCleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Modify Necessary Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List necessary packages\n",
    "import glob as gl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Y:\\Abul\\Conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (53,54,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Load MasterDS_R file\n",
    "MasterDS=pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterDS.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Necessary Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Essential Files\n",
    "MasterDS_R=pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterDS_R.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all data files\n",
    "CompiledSales =pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/CompiledSales.csv\", encoding='utf-8')\n",
    "CompiledSubSheet =pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/CompiledSubSheet.csv\", encoding='utf-8')\n",
    "#CompiledMainSheet =pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/CompiledMainSheet.csv\", encoding='utf-8')\n",
    "CompiledMainSheetSS =pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/CompiledMainSheetSS.csv\", encoding='utf-8')\n",
    "internal_skuRef =pd.read_csv('//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/internal_skuRef.csv', encoding='utf-8')\n",
    "\n",
    "Y2013 = pd.read_csv(\"C:/Users/asheikh/Desktop/Sales Data/Y2013.csv\", encoding='utf-8')\n",
    "Y2014 = pd.read_csv(\"C:/Users/asheikh/Desktop/Sales Data/Y2014.csv\", encoding='utf-8')\n",
    "Y2015 = pd.read_csv(\"C:/Users/asheikh/Desktop/Sales Data/Y2015.csv\", encoding='utf-8')\n",
    "Y2016 = pd.read_csv(\"C:/Users/asheikh/Desktop/Sales Data/Y2016.csv\", encoding='utf-8')\n",
    "Y2017 = pd.read_csv(\"C:/Users/asheikh/Desktop/Sales Data/Y2017.csv\", encoding='utf-8')\n",
    "Y2018 = pd.read_csv(\"C:/Users/asheikh/Desktop/Sales Data/Y2018.csv\", encoding='utf-8')\n",
    "Y2019 = pd.read_csv(\"C:/Users/asheikh/Desktop/Sales Data/Y2019.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate Necessary Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all mainsheet folders \n",
    "def MScheck():\n",
    "\n",
    "    AllBrandFolderPath = \"//192.168.2.32/GoogleDrive/Completed Magento Uploads (v 1.0)\"\n",
    "    AllBrandFolders = os.listdir(AllBrandFolderPath)\n",
    "\n",
    "    for b in range(len(AllBrandFolders)):\n",
    "\n",
    "        BrandPath = AllBrandFolderPath+\"/\"+AllBrandFolders[b]\n",
    "        BrandMSpath = BrandPath+\"/main--*.csv\"\n",
    "        BrandSSpath = BrandPath+\"/sub--*.csv\"\n",
    "        MSfilecount = len(gl.glob(BrandMSpath))\n",
    "        SSfilecount = len(gl.glob(BrandSSpath))\n",
    "        if MSfilecount != 1:\n",
    "            print(AllBrandFolders[b], \"MS\", MSfilecount)\n",
    "        #if SSfilecount != 1:\n",
    "            #print(AllBrandFolders[b], \"SS\", SSfilecount)\n",
    "\n",
    "MScheck() #Excute check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile all column names in MS and create refrence \n",
    "\n",
    "CompiledMainSheet = pd.DataFrame({\"internal_sku\":[]})\n",
    "AllColumns = pd.DataFrame({\"col\":[]})\n",
    "SubsetList = ['internal_sku','delete','type',\n",
    "              'part_type_filter','attribute_set',\n",
    "               'categories','series_parent']\n",
    "AllBrandFolderPath = \"//192.168.2.32/GoogleDrive/Completed Magento Uploads (v 1.0)\"\n",
    "AllBrandFolders = os.listdir(AllBrandFolderPath)\n",
    "\n",
    "for b in range(len(AllBrandFolders)):\n",
    "    brand = AllBrandFolders[b]\n",
    "    print((len(AllBrandFolders)-b), brand)\n",
    " \n",
    "    BrandPath= str(AllBrandFolderPath+\"/\"+brand)\n",
    "    BrandMSpath = BrandPath+\"/main--*.csv\"\n",
    "    filecount = len(gl.glob(BrandMSpath))\n",
    "    if filecount == 1:\n",
    "        MSFile = gl.glob(BrandMSpath)[0]\n",
    "        MS = pd.read_csv(MSFile, encoding='mac_roman')\n",
    "        BrandMS_Col =  pd.DataFrame({\"col\":  list(map(str.strip, (MS.columns))) } )\n",
    "        MS.columns = BrandMS_Col[\"col\"]\n",
    "        MS = MS[MS[\"type\"] == \"simple\"][SubsetList]\n",
    "\n",
    "        CompiledMainSheet = pd.concat([CompiledMainSheet,MS], axis=0, ignore_index=True, sort=False)\n",
    "        \n",
    "#CompiledMainSheet.to_csv (r'192.168.2.32\\Group\\Data Team\\Recommender_System_Location\\1_Reference_Files\\CompiledMainSheet.csv', index = None, header=True) \n",
    "\n",
    "CompiledMainSheetSS = (CompiledMainSheet[~(CompiledMainSheet[\"internal_sku\"].isna())])\n",
    "\n",
    "CompiledMainSheetSS.to_csv(r'\\\\192.168.2.32\\Group\\Data Team\\Recommender_System_Location\\1_Reference_Files\\CompiledMainSheetSS.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile all column names in subsheet and create refrence \n",
    "\n",
    "CompiledSubSheet = pd.DataFrame({\"internal_sku\":[]})\n",
    "    \n",
    "AllBrandFolderPath = \"//192.168.2.32/GoogleDrive/Completed Magento Uploads (v 1.0)\"\n",
    "AllBrandFolders = os.listdir(AllBrandFolderPath)\n",
    "\n",
    "for b in range(len(AllBrandFolders)):\n",
    "    Brand = AllBrandFolders[b]\n",
    "    print((len(AllBrandFolders)-b), Brand)\n",
    "    BrandPath= str(AllBrandFolderPath+\"/\"+Brand)\n",
    "    BrandSSpath = BrandPath+\"/sub--*.csv\"\n",
    "    filecount = len(gl.glob(BrandSSpath))\n",
    "    if filecount >= 1:\n",
    "        for f in range(filecount):\n",
    "            SSFile = gl.glob(BrandSSpath)[f]\n",
    "            SSfile = pd.read_csv(SSFile, encoding='mac_roman')\n",
    "            BrandSS = list(map(str.strip, SSfile.columns))\n",
    "            SSfile.columns = BrandSS\n",
    "            \n",
    "            if (\"start_year\" in BrandSS) == True:\n",
    "                SSfile_ss = SSfile[[\"internal_sku\",\"start_year\",\"make\",\"model\"]]\n",
    "                SSfile_ss.columns = [\"internal_sku\",\"year\",\"make\",\"model\"]\n",
    "            else:\n",
    "                SSfile_ss = SSfile[[\"internal_sku\",\"year\",\"make\",\"model\"]]   \n",
    "                \n",
    "                \n",
    "            SSfile_ss = (SSfile_ss[ ~(SSfile_ss[\"make\"].isna()) & ~(SSfile_ss[\"model\"].isna()) & \n",
    "                          ~(SSfile_ss[\"make\"] == \"ALL\") & ~(SSfile_ss[\"model\"] == \"ALL\") ])\n",
    "            \n",
    "            SSfile_ss[\"make\"] = list(map(str.upper,SSfile_ss[\"make\"]))\n",
    "            SSfile_ss[\"model\"] = list(map(str.upper,SSfile_ss[\"model\"]))\n",
    "\n",
    "            CompiledSubSheet = pd.concat([CompiledSubSheet,SSfile_ss], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "CompiledSubSheet = (CompiledSubSheet[ ~(CompiledSubSheet[\"make\"].isna()) & ~(CompiledSubSheet[\"model\"].isna()) & \n",
    "                          ~(CompiledSubSheet[\"make\"] == \"ALL\") & ~(CompiledSubSheet[\"model\"] == \"ALL\") ])\n",
    "            \n",
    "CompiledSubSheet[\"make\"] = list(map(str.upper,CompiledSubSheet[\"make\"]))\n",
    "CompiledSubSheet[\"model\"] = list(map(str.upper,CompiledSubSheet[\"model\"]))            \n",
    "            \n",
    "CompiledSubSheet.to_csv(r'\\\\192.168.2.32\\Group\\Data Team\\Recommender_System_Location\\1_Reference_Files\\CompiledSubSheet.csv', index = None, header=True) \n",
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify all mismatching skus depening on cost criteria, from up to 2 years prior\n",
    "#Pool all necessary data and create criteria variables\n",
    "internal_skuRef =pd.read_csv('//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/internal_skuRef.csv', encoding='utf-8')\n",
    "CostLimit = 15000 # = (sum of cost per sku)/(PriorYearLimit+1 Years), in this case, skus with >5K/year are considered\n",
    "PriorYearLimit = 2\n",
    "Sales_sku = set(CompiledSales[\"SKU\"].unique())\n",
    "MS_sku = set(CompiledMainSheet[\"internal_sku\"].unique())\n",
    "ISref = set(internal_skuRef[\"SKU\"].unique())\n",
    "CurrentYear = datetime.datetime.now().year\n",
    "LatestMonth = (CompiledSales['Order_Date'].sort_values(ascending=False).reset_index()).iloc[0, :]\n",
    "YearRange = list(range((CurrentYear)-PriorYearLimit, (CurrentYear)+1))\n",
    "\n",
    "#Identify missing internal_skus\n",
    "MissMatch = pd.DataFrame({\"internal_sku\": list((Sales_sku - ISref) - MS_sku)})\n",
    "MissingSkus= CompiledSales[CompiledSales[\"SKU\"].isin(MissMatch[\"internal_sku\"])]\n",
    "\n",
    "MissingSkusBrands = (MissingSkus[MissingSkus[\"OD_Year\"].isin(YearRange)]\n",
    "                     .groupby([\"Brands\"])[\"Product Cost (CAD)\"]\n",
    "                     .agg(\"sum\")\n",
    "                     .reset_index())\n",
    "                    #.sort_values(\"Product Cost (CAD)\", ascending=False)\n",
    "\n",
    "MissingSkusBrands= MissingSkusBrands[MissingSkusBrands[\"Product Cost (CAD)\"] >= CostLimit]\n",
    "KeyMissingSkus= (pd.DataFrame({\"internal_sku\": (MissingSkus[MissingSkus[\"Brands\"]\n",
    "                            .isin(MissingSkusBrands[\"Brands\"])][\"SKU\"].unique())}))\n",
    "\n",
    "print(len(KeyMissingSkus)) #Print out number of skus that need fixing\n",
    "KeyMissingSkus.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/KeyMissingSkus.csv', index = None, header=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile and subset data sources\n",
    "CompiledSales_R = pd.concat([Y2013,Y2014], axis=0, ignore_index=True, sort=False)\n",
    "CompiledSales_R = pd.concat([CompiledSales_R,Y2015], axis=0, ignore_index=True, sort=False)\n",
    "CompiledSales_R = pd.concat([CompiledSales_R,Y2016], axis=0, ignore_index=True, sort=False)\n",
    "CompiledSales_R = pd.concat([CompiledSales_R,Y2017], axis=0, ignore_index=True, sort=False)\n",
    "CompiledSales_R = pd.concat([CompiledSales_R,Y2018], axis=0, ignore_index=True, sort=False)\n",
    "CompiledSales_R = pd.concat([CompiledSales_R,Y2019], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "CompiledSales_R = CompiledSales_R[ (CompiledSales_R[\"Year\"] != \"All\") & (CompiledSales_R[\"Year\"] != \"ALL\") \n",
    "                             & (CompiledSales_R[\"Year\"] != \"B1800\")\n",
    "                             & (CompiledSales_R[\"Year\"] != \"nofit\")\n",
    "                             & ~CompiledSales_R[\"Year\"].isnull()]\n",
    "\n",
    "CompiledSales_R['Order_Date'] = pd.to_datetime(CompiledSales_R['Order Date'], format= \"%d-%b-%y\")\n",
    "CompiledSales_R['OD_Year'] = pd.to_numeric(CompiledSales_R['Order_Date'].dt.strftime('%Y'))\n",
    "CompiledSales_R['OD_MonthNum'] = CompiledSales_R['Order_Date'].dt.strftime('%m')\n",
    "CompiledSales_R['OD_MonthLab'] = CompiledSales_R['Order_Date'].dt.strftime('%B')\n",
    "CompiledSales_R['OD_MonthDay'] = CompiledSales_R['Order_Date'].dt.strftime('%d')\n",
    "CompiledSales_R['OD_WeekDay'] = CompiledSales_R['Order_Date'].dt.strftime('%A')\n",
    "CompiledSales_R[\"Product Cost (CAD)\"] = pd.to_numeric(CompiledSales_R[\"Product Cost (CAD)\"])\n",
    "\n",
    "CompiledSales = CompiledSales_R\n",
    "\n",
    "#Clean Sales data skus\n",
    "CompiledSales = CompiledSales.merge(internal_skuRef, on = \"SKU\", how = 'outer')\n",
    "CompiledSales[\"internal_sku\"] = CompiledSales[~(CompiledSales[\"SKU\"].isin(internal_skuRef[\"SKU\"]))][\"SKU\"]\n",
    "\n",
    "#Perform sku count match\n",
    "A = len(CompiledSales[\"SKU\"].unique())\n",
    "B = len(CompiledSales[\"internal_sku\"].unique())\n",
    "C = len(internal_skuRef)\n",
    "E = len(CompiledSales[CompiledSales[\"internal_sku\"].isna() == True][\"SKU\"].unique())\n",
    "\n",
    "if (A == (B + E - 1)) == True:\n",
    "    CompiledSales.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/CompiledSales.csv', index = None, header=True) \n",
    "else:\n",
    "    print(\"Issue Detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create & Clean MasterDS_R file\n",
    "MasterDS_R = CompiledSales.merge(CompiledMainSheetSS, on = \"internal_sku\", how = 'inner')\n",
    "MasterDS_R.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterDS_R.csv', index = None, header=True) \n",
    "\n",
    "#Clean Up Series data\n",
    "SeriesRef = list(MasterDS_R[\"series_parent\"].unique())\n",
    "SeriesRefNew = pd.DataFrame(columns = [\"series_parent\", \"series_parent_New\"])\n",
    "for s in range(len(SeriesRef)):\n",
    "    string = SeriesRef[s]\n",
    "    SepList = string.split(\";\")\n",
    "    CompList = pd.DataFrame({\"series_parent\":string, \"series_parent_New\":SepList})\n",
    "    SeriesRefNew = SeriesRefNew.append(CompList)\n",
    "SeriesRefNew = SeriesRefNew[SeriesRefNew[\"series_parent\"] != \"Discontinued\"]\n",
    "\n",
    "#Clean up Part Type Data\n",
    "PTRef = list((MasterDS_R[~(MasterDS_R[\"part_type_filter\"].isna())][\"part_type_filter\"]).unique())\n",
    "PTRefNew = pd.DataFrame(columns = [\"part_type_filter\", \"part_type_filter_New\"])\n",
    "for s in range(len(PTRef)):\n",
    "    string = PTRef[s]\n",
    "    SepList = string.split(\";\")\n",
    "    CompList = pd.DataFrame({\"part_type_filter\":string, \"part_type_filter_New\":SepList})\n",
    "    PTRefNew = PTRefNew.append(CompList)\n",
    "PTRefNew = PTRefNew[PTRefNew[\"part_type_filter\"] != \"Discontinued\"]\n",
    "\n",
    "#Clean up categories Data\n",
    "CatRef = list((MasterDS_R[~(MasterDS_R[\"categories\"].isna())][\"categories\"]).unique())\n",
    "CatRefNew = pd.DataFrame(columns = [\"categories\", \"categories_New\", \"L1\", \"L2\", \"L3\"])\n",
    "for s in range(len(CatRef)):\n",
    "    string = CatRef[s]\n",
    "    SepList = string.split(\";\")\n",
    "    CompList = pd.DataFrame({\"categories\":string, \"categories_New\":SepList})\n",
    "    CatRefNew = CatRefNew.append(CompList)\n",
    "CatRefNew = CatRefNew[(CatRefNew[\"categories\"] != \"Discontinued\")]\n",
    "CatRefNew = CatRefNew[(~(CatRefNew['categories_New'].str.contains(\"Brands/\")))].reset_index()\n",
    "for s in range(len(CatRefNew)):\n",
    "    string = CatRefNew.iloc[s,5]\n",
    "    SepList = string.split(\"/\")\n",
    "    if len(SepList) == 3:\n",
    "        L1 = SepList[0]\n",
    "        L2 = SepList[1]\n",
    "        L3 = SepList[2]\n",
    "    elif len(SepList) == 2:\n",
    "        L1 = SepList[0]\n",
    "        L2 = SepList[1]\n",
    "        L3 = \"\"  \n",
    "    elif len(SepList) == 1:\n",
    "        L1 = SepList[0]\n",
    "        L2 = \"\"\n",
    "        L3 = \"\"  \n",
    "    CatRefNew.loc[s, \"L1\"] = L1\n",
    "    CatRefNew.loc[s, \"L2\"] = L2\n",
    "    CatRefNew.loc[s, \"L3\"] = L3\n",
    "CatRefNew2 = CatRefNew[[\"categories\", \"L1\", \"L2\", \"L3\"]]\n",
    "\n",
    "#Clean MM Data\n",
    "#Make Values all Cap\n",
    "#STEP ONE\n",
    "MasterDS_R = (MasterDS_R[ ~(MasterDS_R[\"Make\"].isna()) & ~(MasterDS_R[\"Model\"].isna()) & \n",
    "                          ~(MasterDS_R[\"Model\"] == \"ALL\") & ~(MasterDS_R[\"Model\"] == \"ALL\") ]).reset_index()\n",
    "MasterDS_R[\"Make\"] = list(map(str.upper,MasterDS_R[\"Make\"]))\n",
    "MasterDS_R[\"Model\"] = list(map(str.upper,MasterDS_R[\"Model\"]))\n",
    "MasterDS_R = MasterDS_R.drop([\"index\"], axis=1)\n",
    "MasterDS_R = MasterDS_R.reset_index()\n",
    "\n",
    "CompiledSubSheetSS = CompiledSubSheet[[\"make\", \"model\"]]\n",
    "SSMMref = CompiledSubSheet[\"make\"]+\";\"+CompiledSubSheet[\"model\"]\n",
    "SSMMref = pd.DataFrame({\"SSref\":list(SSMMref)})\n",
    "SSMMref = SSMMref[\"SSref\"].unique()\n",
    "SSMMref = pd.DataFrame({\"SSref\":list(SSMMref)})\n",
    "\n",
    "MSDref = pd.DataFrame({\"MSDJoin\":MasterDS_R[\"Make\"]+\";\"+MasterDS_R[\"Model\"]})\n",
    "MSDref = pd.DataFrame({\"MSDJoin\":list(MSDref[\"MSDJoin\"].unique())})\n",
    "\n",
    "MM_MissMatch = pd.DataFrame({\"MSDJoin\":list(set(MSDref[\"MSDJoin\"]) - set(SSMMref[\"SSref\"]))})\n",
    "\n",
    "SSMMref.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/SSMMref.csv', index = None, header=True) \n",
    "MM_MissMatch.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MM_MissMatch.csv', index = None, header=True) \n",
    "\n",
    "#STEP TWO\n",
    "MakeModelRef =pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MakeModelRef.csv\", encoding='utf-8')\n",
    "\n",
    "MasterDS_R[\"Make\"] \n",
    "MasterDS_R[\"Model\"]\n",
    "\n",
    "for m in range(len(MakeModelRef)):\n",
    "    Make_error = MakeModelRef.loc[1, \"Make_error\"]\n",
    "    Model_error = MakeModelRef.loc[1, \"Model_error\"]\n",
    "    Make_clean = MakeModelRef.loc[1, \"Make_clean\"]\n",
    "    Model_clean = MakeModelRef.loc[1, \"Model_clean\"]\n",
    "    \n",
    "    matchdf = MasterDS_R[(MasterDS_R[\"Make\"] == Make_error) & (MasterDS_R[\"Model\"] == Model_error) ]\n",
    "    matchindex = list(matchdf[\"index\"])\n",
    "    for i in range(len(matchindex)):\n",
    "        MasterDS_R.loc[matchindex[0], \"Make\"] = Make_clean\n",
    "        MasterDS_R.loc[matchindex[0], \"Model\"] = Model_clean\n",
    "\n",
    "#STEP THREE\n",
    "MasterDS = MasterDS_R.merge(SeriesRefNew, on = \"series_parent\", how = \"outer\")\n",
    "MasterDS = MasterDS_R.merge(PTRefNew, on = \"part_type_filter\", how = \"outer\")\n",
    "\n",
    "MasterDS.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterDS.csv', index = None, header=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct YMM Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Base df\n",
    "YMMmonRef = MasterDS.groupby(['Year', 'Make', 'Model', \"OD_MonthNum\"]).agg(\"count\").reset_index()[['Year', 'Make', 'Model', \"OD_MonthNum\"]]\n",
    "YMMRef = MasterDS.groupby(['Year', 'Make', 'Model']).agg(\"count\").reset_index()[['Year', 'Make', 'Model']]\n",
    "MMRef = MasterDS.groupby(['Make', 'Model']).agg(\"count\").reset_index()[['Make', 'Model']]\n",
    "MRef = MasterDS.groupby([ 'Make']).agg(\"count\").reset_index()[['Make']]\n",
    "MasterRecomDoc = pd.DataFrame(columns = ['Year', 'Make', 'Model', 'OD_MonthNum', 'Sku_0', 'Sku_1'])\n",
    "\n",
    "#Desired Brand per Ref\n",
    "for m in range(len(MRef)):\n",
    "    make = MRef.iloc[m,0]\n",
    "    \n",
    "    SeriesCount = (MasterDS[MasterDS[\"Make\"] == make]\n",
    "     .groupby(\"series_parent_New\")\n",
    "     .agg(\"count\")\n",
    "     .sort_values(\"Order Date\", ascending = False)\n",
    "     .reset_index()[[\"series_parent_New\", \"Order Date\"]])\n",
    "    \n",
    "    if len(SeriesCount) >1:\n",
    "        Max = 2\n",
    "    else:\n",
    "        Max = len(SeriesCount)\n",
    "\n",
    "    for s in range(0, Max):\n",
    "        Col = \"Sku_\"+ str(s)\n",
    "        MRef.loc[m,Col] = SeriesCount.iloc[s,0]\n",
    "    \n",
    "for m in range(len(MMRef)):\n",
    "    make = MMRef.iloc[m,0]\n",
    "    model = MMRef.iloc[m,1]  \n",
    "\n",
    "    SeriesCount = (MasterDS[(MasterDS[\"Model\"] == model) & (MasterDS[\"Make\"] == make) ]\n",
    "     .groupby(\"series_parent_New\")\n",
    "     .agg(\"count\")\n",
    "     .sort_values(\"Order Date\", ascending = False)\n",
    "     .reset_index()[[\"series_parent_New\", \"Order Date\"]])\n",
    "        \n",
    "    if len(SeriesCount) >1:\n",
    "        Max = 2\n",
    "    else:\n",
    "        Max = len(SeriesCount)\n",
    "\n",
    "    for s in range(0, Max):\n",
    "        Col = \"Sku_\"+ str(s)\n",
    "        MMRef.loc[m,Col] = SeriesCount.iloc[s,0]\n",
    "\n",
    "for m in range(len(YMMRef)):\n",
    "    year = YMMRef.iloc[m,0]\n",
    "    make = YMMRef.iloc[m,1]\n",
    "    model = YMMRef.iloc[m,2]\n",
    "\n",
    "    print(year, make, model)\n",
    "    subset = MasterDS[(MasterDS[\"Year\"] == year) & (MasterDS[\"Make\"] == make) & (MasterDS[\"Model\"] == model)]\n",
    "    if list(pd.isnull(subset.Brands))[0] == False:\n",
    "        SeriesCount = (subset\n",
    "         .groupby(\"series_parent_New\")\n",
    "         .agg(\"count\")\n",
    "         .sort_values(\"Order Date\", ascending = False)\n",
    "         .reset_index()[[\"series_parent_New\", \"Order Date\"]])\n",
    "        \n",
    "        if len(SeriesCount) >1:\n",
    "            Max = 2\n",
    "        else:\n",
    "            Max = len(SeriesCount)\n",
    "            \n",
    "        for s in range(0, Max):\n",
    "            Col = \"Sku_\"+ str(s)\n",
    "            YMMRef.loc[m,Col] = SeriesCount.iloc[s,0] \n",
    "    \n",
    "\n",
    "for m in range(len(YMMmonRef)):\n",
    "    year = YMMmonRef.iloc[m,0]\n",
    "    make = YMMmonRef.iloc[m,1]\n",
    "    model = YMMmonRef.iloc[m,2]\n",
    "    month = YMMmonRef.iloc[m,3] \n",
    "    \n",
    "    print(year, make, model)\n",
    "    subset = (MasterDS[(MasterDS[\"Year\"] == year) & \n",
    "                            (MasterDS[\"Make\"] == make) &\n",
    "                            (MasterDS[\"OD_MonthNum\"] == month) & \n",
    "                            (MasterDS[\"Model\"] == model)])\n",
    "    if len(subset)>=1:\n",
    "        if list(pd.isnull(subset.Brands))[0] == False:\n",
    "            SeriesCount = (subset\n",
    "             .groupby(\"series_parent_New\")\n",
    "             .agg(\"count\")\n",
    "             .sort_values(\"Order Date\", ascending = False)\n",
    "             .reset_index()[[\"series_parent_New\", \"Order Date\"]])\n",
    "\n",
    "            if len(SeriesCount) >1:\n",
    "                Max = 2\n",
    "            else:\n",
    "                Max = len(SeriesCount)\n",
    "\n",
    "            for s in range(0, Max):\n",
    "                Col = \"Sku_\"+ str(s)\n",
    "                YMMmonRef.loc[m,Col] = SeriesCount.iloc[s,0]\n",
    "\n",
    "#Combine all recommendation docs\n",
    "YMMRef[\"OD_MonthNum\"] = \"All\"\n",
    "MMRef[\"Year\"] = \"All\"\n",
    "MMRef[\"OD_MonthNum\"] = \"All\"\n",
    "MRef[\"Year\"] = \"All\"\n",
    "MRef[\"OD_MonthNum\"] = \"All\"\n",
    "MRef[\"Model\"] = \"All\"\n",
    "\n",
    "MasterRecomDoc = MasterRecomDoc.append(YMMmonRef, sort=False)\n",
    "MasterRecomDoc = MasterRecomDoc.append(YMMRef, sort=False)\n",
    "MasterRecomDoc = MasterRecomDoc.append(MMRef, sort=False)\n",
    "MasterRecomDoc = MasterRecomDoc.append(MRef, sort=False)\n",
    "\n",
    "MasterRecomDoc.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterRecomDoc.csv', index = None, header=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Base df\n",
    "YMMmonRef = MasterDS.groupby(['Year', 'Make', 'Model', \"OD_MonthNum\"]).agg(\"count\").reset_index()[['Year', 'Make', 'Model', \"OD_MonthNum\"]]\n",
    "YMMRef = MasterDS.groupby(['Year', 'Make', 'Model']).agg(\"count\").reset_index()[['Year', 'Make', 'Model']]\n",
    "MMRef = MasterDS.groupby(['Make', 'Model']).agg(\"count\").reset_index()[['Make', 'Model']]\n",
    "MRef = MasterDS.groupby([ 'Make']).agg(\"count\").reset_index()[['Make']]\n",
    "MasterRecomDoc = pd.DataFrame(columns = ['Year', 'Make', 'Model', 'OD_MonthNum', 'Sku_0', 'Sku_1'])\n",
    "\n",
    "\n",
    "MasterDS[\"part_type_filter_New\"]\n",
    "#Desired Brand per Ref\n",
    "for m in range(len(MRef)):\n",
    "    make = MRef.iloc[m,0]\n",
    "    \n",
    "    SeriesCount = (MasterDS[MasterDS[\"Make\"] == make]\n",
    "     .groupby(\"part_type_filter_New\")\n",
    "     .agg(\"count\")\n",
    "     .sort_values(\"Order Date\", ascending = False)\n",
    "     .reset_index()[[\"part_type_filter_New\", \"Order Date\"]])\n",
    "    \n",
    "    if len(SeriesCount) >1:\n",
    "        Max = 2\n",
    "    else:\n",
    "        Max = len(SeriesCount)\n",
    "\n",
    "    for s in range(0, Max):\n",
    "        Col = \"Sku_\"+ str(s)\n",
    "        MRef.loc[m,Col] = SeriesCount.iloc[s,0]\n",
    "    \n",
    "for m in range(len(MMRef)):\n",
    "    make = MMRef.iloc[m,0]\n",
    "    model = MMRef.iloc[m,1]  \n",
    "\n",
    "    SeriesCount = (MasterDS[(MasterDS[\"Model\"] == model) & (MasterDS[\"Make\"] == make) ]\n",
    "     .groupby(\"part_type_filter_New\")\n",
    "     .agg(\"count\")\n",
    "     .sort_values(\"Order Date\", ascending = False)\n",
    "     .reset_index()[[\"part_type_filter_New\", \"Order Date\"]])\n",
    "        \n",
    "    if len(SeriesCount) >1:\n",
    "        Max = 2\n",
    "    else:\n",
    "        Max = len(SeriesCount)\n",
    "\n",
    "    for s in range(0, Max):\n",
    "        Col = \"Sku_\"+ str(s)\n",
    "        MMRef.loc[m,Col] = SeriesCount.iloc[s,0]\n",
    "\n",
    "for m in range(len(YMMRef)):\n",
    "    year = YMMRef.iloc[m,0]\n",
    "    make = YMMRef.iloc[m,1]\n",
    "    model = YMMRef.iloc[m,2]\n",
    "\n",
    "    print(year, make, model)\n",
    "    subset = MasterDS[(MasterDS[\"Year\"] == year) & (MasterDS[\"Make\"] == make) & (MasterDS[\"Model\"] == model)]\n",
    "    if list(pd.isnull(subset.Brands))[0] == False:\n",
    "        SeriesCount = (subset\n",
    "         .groupby(\"part_type_filter_New\")\n",
    "         .agg(\"count\")\n",
    "         .sort_values(\"Order Date\", ascending = False)\n",
    "         .reset_index()[[\"part_type_filter_New\", \"Order Date\"]])\n",
    "        \n",
    "        if len(SeriesCount) >1:\n",
    "            Max = 2\n",
    "        else:\n",
    "            Max = len(SeriesCount)\n",
    "            \n",
    "        for s in range(0, Max):\n",
    "            Col = \"Sku_\"+ str(s)\n",
    "            YMMRef.loc[m,Col] = SeriesCount.iloc[s,0] \n",
    "\n",
    "for m in range(len(YMMRef)):\n",
    "    month = YMMmonRef.iloc[m,3]\n",
    "    make = YMMRef.iloc[m,1]\n",
    "    model = YMMRef.iloc[m,2]\n",
    "\n",
    "    print(month, make, model)\n",
    "    subset = MasterDS[(MasterDS[\"OD_MonthNum\"] == month) & (MasterDS[\"Make\"] == make) & (MasterDS[\"Model\"] == model)]\n",
    "    if len(subset)>0:\n",
    "        if list(pd.isnull(subset.Brands))[0] == False:\n",
    "            SeriesCount = (subset\n",
    "             .groupby(\"part_type_filter_New\")\n",
    "             .agg(\"count\")\n",
    "             .sort_values(\"Order Date\", ascending = False)\n",
    "             .reset_index()[[\"part_type_filter_New\", \"Order Date\"]])\n",
    "\n",
    "            if len(SeriesCount) >1:\n",
    "                Max = 2\n",
    "            else:\n",
    "                Max = len(SeriesCount)\n",
    "\n",
    "            for s in range(0, Max):\n",
    "                Col = \"Sku_\"+ str(s)\n",
    "                YMMRef.loc[m,Col] = SeriesCount.iloc[s,0] \n",
    "\n",
    "for m in range(len(YMMmonRef)):\n",
    "    year = YMMmonRef.iloc[m,0]\n",
    "    make = YMMmonRef.iloc[m,1]\n",
    "    model = YMMmonRef.iloc[m,2]\n",
    "    month = YMMmonRef.iloc[m,3] \n",
    "    \n",
    "    print(year, make, model)\n",
    "    subset = (MasterDS[(MasterDS[\"Year\"] == year) & \n",
    "                            (MasterDS[\"Make\"] == make) &\n",
    "                            (MasterDS[\"OD_MonthNum\"] == month) & \n",
    "                            (MasterDS[\"Model\"] == model)])\n",
    "    if len(subset)>=1:\n",
    "        if list(pd.isnull(subset.Brands))[0] == False:\n",
    "            SeriesCount = (subset\n",
    "             .groupby(\"part_type_filter_New\")\n",
    "             .agg(\"count\")\n",
    "             .sort_values(\"Order Date\", ascending = False)\n",
    "             .reset_index()[[\"part_type_filter_New\", \"Order Date\"]])\n",
    "\n",
    "            if len(SeriesCount) >1:\n",
    "                Max = 2\n",
    "            else:\n",
    "                Max = len(SeriesCount)\n",
    "\n",
    "            for s in range(0, Max):\n",
    "                Col = \"Sku_\"+ str(s)\n",
    "                YMMmonRef.loc[m,Col] = SeriesCount.iloc[s,0]\n",
    "\n",
    "#Combine all recommendation docs\n",
    "YMMRef[\"OD_MonthNum\"] = \"All\"\n",
    "MMRef[\"Year\"] = \"All\"\n",
    "MMRef[\"OD_MonthNum\"] = \"All\"\n",
    "MRef[\"Year\"] = \"All\"\n",
    "MRef[\"OD_MonthNum\"] = \"All\"\n",
    "MRef[\"Model\"] = \"All\"\n",
    "\n",
    "MasterRecomDoc = MasterRecomDoc.append(YMMmonRef, sort=False)\n",
    "MasterRecomDoc = MasterRecomDoc.append(YMMRef, sort=False)\n",
    "MasterRecomDoc = MasterRecomDoc.append(MMRef, sort=False)\n",
    "MasterRecomDoc = MasterRecomDoc.append(MRef, sort=False)\n",
    "\n",
    "MasterRecomDoc.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterRecomDocPT.csv', index = None, header=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Product Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Vector Calculations\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def VecMeg(vec):\n",
    "    return(np.sqrt(sum(vec**2)))\n",
    "    \n",
    "\n",
    "a = np.array([5, 0, 3, 0, 2, 0, 0, 2, 0, 0])\n",
    "b = np.array([3, 0, 2, 0, 1, 1, 0, 1, 0, 1])\n",
    "\n",
    "\n",
    "np.arange(a)\n",
    "\n",
    "A = np.array([[ 0,  2,  4],\n",
    "       [ 6,  8, 10],\n",
    "       [12, 14, 16],\n",
    "       [18, 20, 22]])\n",
    "\n",
    "\n",
    "a = np.array([ 0,  2,  4])\n",
    "b = np.array([ 6,  8, 10])\n",
    "\n",
    "a_meg = np.sqrt(sum(a**2))\n",
    "b_meg = np.sqrt(sum(b**2))\n",
    "\n",
    "CosineSim = sum(a*b)/(a_meg*b_meg)\n",
    "EuclidDist = np.sqrt(sum((a - b)**2))\n",
    "NewAngle = math.acos(CosineSim) + math.radians(10)\n",
    "SectAreaSim = np.absolute( a_meg - b_meg) \n",
    "\n",
    "TS_SS = (a_meg*b_meg*math.sin(NewAngle)*NewAngle*math.pi*((EuclidDist+SectAreaSim)**2))/720\n",
    "TS_SS\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(A))\n",
    "\n",
    "def cossim(A):\n",
    "    profile = cProfile.Profile()\n",
    "    profile.enable()\n",
    "    \n",
    "    mat = np.zeros((A.shape[0], A.shape[0]))\n",
    "    \n",
    "    for ref in range(A.shape[0]):\n",
    "        for com in range(A.shape[0]):  \n",
    "            \n",
    "            a = A[ref]\n",
    "            b = A[com]\n",
    "        \n",
    "            a_meg = np.sqrt(np.sum(a**2))\n",
    "            b_meg = np.sqrt(np.sum(b**2))\n",
    "            \n",
    "            CosineSim = float(\"{0:.4f}\".format(np.sum(a*b)/(a_meg*b_meg)))\n",
    "            EuclidDist = np.sqrt(np.sum((a - b)**2))\n",
    "            NewAngle = math.acos(CosineSim) + math.radians(10)\n",
    "            SectAreaSim = np.absolute( a_meg - b_meg) \n",
    "\n",
    "            TS_SS = (a_meg*b_meg*math.sin(NewAngle)*NewAngle*math.pi*((EuclidDist+SectAreaSim)**2))/720\n",
    "            #print(TS_SS)\n",
    "            mat[ref][com] = TS_SS\n",
    "            \n",
    "    #return(mat)\n",
    "    profile.disable()\n",
    "    ps = pstats.Stats(profile)\n",
    "    ps.print_stats()\n",
    "\n",
    "\n",
    "sermat = np.array(MRefMaster.iloc[:, 1:1000]).transpose()\n",
    "sermat.shape\n",
    "\n",
    "ref = 1\n",
    "com = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "profile = cProfile.Profile()\n",
    "\n",
    "\n",
    "profile.runcall(cossim(A = sermat))\n",
    "ps = pstats.Stats(profile)\n",
    "ps.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(A))\n",
    "\n",
    "check_pairwise_arrays(A, A)\n",
    "\n",
    "X = Y = check_array(A, accept_sparse='csr', dtype=dtype)\n",
    "\n",
    "A = np.array(MRefMaster.iloc[:, 1:])\n",
    "B = A.T\n",
    "\n",
    "np.multiply(A,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getsource(cosine_similarity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(X, Y=None, dense_output=True):\n",
    "    \"\"\"Compute cosine similarity between samples in X and Y.\n",
    "\n",
    "    Cosine similarity, or the cosine kernel, computes similarity as the\n",
    "    normalized dot product of X and Y:\n",
    "\n",
    "        K(X, Y) = <X, Y> / (||X||*||Y||)\n",
    "\n",
    "    On L2-normalized data, this function is equivalent to linear_kernel.\n",
    "\n",
    "    Read more in the :ref:`User Guide <cosine_similarity>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray or sparse array, shape: (n_samples_X, n_features)\n",
    "        Input data.\n",
    "\n",
    "    Y : ndarray or sparse array, shape: (n_samples_Y, n_features)\n",
    "        Input data. If ``None``, the output will be the pairwise\n",
    "        similarities between all samples in ``X``.\n",
    "\n",
    "    dense_output : boolean (optional), default True\n",
    "        Whether to return dense output even when the input is sparse. If\n",
    "        ``False``, the output is sparse if both input arrays are sparse.\n",
    "\n",
    "        .. versionadded:: 0.17\n",
    "           parameter ``dense_output`` for dense output.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kernel matrix : array\n",
    "        An array with shape (n_samples_X, n_samples_Y).\n",
    "    \"\"\"\n",
    "    # to avoid recursive import\n",
    "\n",
    "    X, Y = check_pairwise_arrays(X, Y)\n",
    "\n",
    "    X_normalized = normalize(X, copy=True)\n",
    "    if X is Y:\n",
    "        Y_normalized = X_normalized\n",
    "    else:\n",
    "        Y_normalized = normalize(Y, copy=True)\n",
    "\n",
    "    K = safe_sparse_dot(X_normalized, Y_normalized.T,\n",
    "                        dense_output=dense_output)\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Reference df\n",
    "MasterDS_new = MasterDS[['Make', 'Model', \"series_parent_New\"]]\n",
    "MasterDS_new[\"series_parent_Two\"] = MasterDS_new[\"series_parent_New\"]\n",
    "\n",
    "YMMRef = MasterDS.groupby(['Year', 'Make', 'Model']).agg(\"count\").reset_index()[['Year', 'Make', 'Model']]\n",
    "MMRef = MasterDS.groupby(['Make', 'Model']).agg(\"count\").reset_index()[['Make', 'Model']]\n",
    "MRef = MasterDS.groupby([ 'Make']).agg(\"count\").reset_index()[['Make']]\n",
    "\n",
    "seriesRef = pd.DataFrame({\"series_parent_New\":MasterDS.series_parent_New.unique()})\n",
    "seriesRef = seriesRef[~seriesRef[\"series_parent_New\"].isna()].reset_index()[[\"series_parent_New\"]]\n",
    "\n",
    "TallySeriesRef = seriesRef\n",
    "\n",
    "a = 1\n",
    "b = 2\n",
    "m = 1\n",
    "\n",
    "for a in range(len(seriesRef)):\n",
    "    SeriesA = seriesRef.loc[a, \"series_parent_New\"]\n",
    "    TallySeries = TallySeriesRef\n",
    "    TallySeries[\"count\"] = 0\n",
    "    \n",
    "    for b in range(len(seriesRef)):  \n",
    "        SeriesB = seriesRef.loc[b, \"series_parent_New\"]\n",
    "        \n",
    "        if (SeriesA != SeriesB) == True:\n",
    "            for m in range(len(MMRef)):  \n",
    "                make = MMRef.loc[m, \"Make\"]\n",
    "                model = MMRef.loc[m, \"Model\"]\n",
    "                \n",
    "                result = MasterDS_new[(MasterDS_new[\"Make\"] == make) &\n",
    "                         (MasterDS_new[\"Model\"] == model) &\n",
    "                         (MasterDS_new[\"series_parent_New\"] == SeriesA) &\n",
    "                         (MasterDS_new[\"series_parent_Two\"] == SeriesB)\n",
    "                         ]\n",
    "                print(len(result), make, model, SeriesA, SeriesB)\n",
    "                TallySeries.loc[b, \"count\"] = TallySeries.loc[b, \"count\"] + len(result)\n",
    "\n",
    "                \n",
    "                \n",
    "#Creating YMM & series matrix\n",
    "\n",
    "seriesRef\n",
    "MMRef\n",
    "MasterDS_new\n",
    "\n",
    "a= 1\n",
    "#Using Make and Model\n",
    "for s in range(len(seriesRef)):\n",
    "    Series = seriesRef.loc[a, \"series_parent_New\"]\n",
    "    for m in range(len(MMRef)):  \n",
    "        make = MMRef.loc[m, \"Make\"]\n",
    "        model = MMRef.loc[m, \"Model\"]\n",
    "\n",
    "        result = MasterDS_new[(MasterDS_new[\"Make\"] == make) &\n",
    "             (MasterDS_new[\"Model\"] == model) &\n",
    "             (MasterDS_new[\"series_parent_New\"] == Series)\n",
    "             ]\n",
    "        \n",
    "        MMRef.loc[m, Series] = len(result)\n",
    "                \n",
    "        print(len(seriesRef) - s, len(result), make, model)\n",
    "        \n",
    "        \n",
    "#Use only Model\n",
    "for s in range(len(seriesRef)):\n",
    "    Series = seriesRef.loc[s, \"series_parent_New\"]\n",
    "    for m in range(len(MRef)):  \n",
    "        make = MRef.loc[m, \"Make\"]\n",
    "\n",
    "        result = MasterDS_new[(MasterDS_new[\"Make\"] == make) &\n",
    "             (MasterDS_new[\"series_parent_New\"] == Series)\n",
    "             ]\n",
    "        \n",
    "        MRef.loc[m, Series] = len(result)\n",
    "                \n",
    "        print(len(seriesRef) - s, len(result), make)\n",
    "        \n",
    "MRef.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MRefMaster.csv', index = None, header=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute angle/distance\n",
    "MRefMaster=pd.read_csv('//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MRefMaster.csv', encoding='utf-8')\n",
    "seriesRef = pd.DataFrame({\"series_parent_New\":MasterDS.series_parent_New.unique()})\n",
    "seriesRef = seriesRef[~seriesRef[\"series_parent_New\"].isna()].reset_index()[[\"series_parent_New\"]]\n",
    "\n",
    "\n",
    "for a in range(len(seriesRef)):\n",
    "    \n",
    "    Similaritydf = pd.DataFrame(columns =  [\"SeriesA\", \"SeriesB\", \"Dist\", \"Ang\"])\n",
    "\n",
    "    for b in range(len(seriesRef)):\n",
    "        SeriesA = seriesRef.loc[a, \"series_parent_New\"]\n",
    "        SeriesB = seriesRef.loc[b, \"series_parent_New\"]\n",
    "\n",
    "        x = np.array(MRefMaster.loc[:, SeriesA])\n",
    "        y = np.array(MRefMaster.loc[:, SeriesB])\n",
    "\n",
    "        Dist = np.sqrt(np.sum((x - y) ** 2))\n",
    "        Ang = np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))\n",
    "        \n",
    "        data = list([SeriesA,SeriesB, Dist, Ang])\n",
    "\n",
    "        Similaritydf = Similaritydf.append(pd.Series(data, index=Similaritydf.columns),  ignore_index=True)\n",
    "\n",
    "        print(SeriesB, Dist, Ang)\n",
    "        \n",
    "    path = \"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/SeriesRecom/\" + SeriesA+\".csv\"\n",
    "    Similaritydf.to_csv(path, index = None, header=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct RC GUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out the layout of the display\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "#Make the frames\n",
    "TopFrame = Frame(root)\n",
    "TopFrame.pack()\n",
    "\n",
    "\n",
    "label = Label(root)\n",
    "label.pack()\n",
    "\n",
    "root.title('Update Schedule Predictor')\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to pull and subset csv without pandas\n",
    "import numpy as np\n",
    "\n",
    "file = \"//TDOTFS01/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterRecomDoc.csv\"\n",
    "data = np.genfromtxt(file, delimiter=',', names=True, dtype='object')\n",
    "\n",
    "np.loadtxt(file)\n",
    "\n",
    "np.loadtxt(file, dtype={'names': ('Year','Make','Model','OD_MonthNum','Sku_0','Sku_1'),'formats': ('S1', 'i4', 'f4', 'S1', 'i4', 'f4')})\n",
    "\n",
    "\n",
    "MasterDS=pd.read_csv(\"//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/MasterDS.csv\", encoding='utf-8')\n",
    "\n",
    "\n",
    "A = MasterDS.groupby(['Make','Model', 'Year', \"OD_Year\"], as_index=False).agg(\"count\")[[\"Make\", \"Model\", \"index\"]]\n",
    "B = A.groupby(['Make','Model'], as_index=False)[\"index\"].agg(\"mean\")[[\"Make\", \"Model\", \"index\"]]\n",
    "B.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/B.csv', index = None, header=True) \n",
    "\n",
    "A = MasterDS.groupby(['Make','Model', 'Year', \"OD_Year\"], as_index=False)[\"Product Cost (CAD)\"].agg(\"sum\")[[\"Make\", \"Model\", \"Year\", \"OD_Year\", \"Product Cost (CAD)\"]]\n",
    "C = A.groupby(['Make','Model'], as_index=False)[\"Product Cost (CAD)\"].agg(\"mean\")[[\"Make\", \"Model\", \"Product Cost (CAD)\"]]\n",
    "D.to_csv(r'//192.168.2.32/Group/Data Team/Recommender_System_Location/1_Reference_Files/B.csv', index = None, header=True) \n",
    "\n",
    "D = B.merge(C, on = ['Make','Model'], how= \"outer\")\n",
    "\n",
    "list(MasterDS.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Unconnected Functions & Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YMM + Month + Parttype + Province\n",
    "\n",
    "Recommended skus <- Dependent on average Basket size which seems to be 1.3 per order. But I'll use 5 just to be safe.\n",
    "#np.mean(CompiledSales[CompiledSales[\"OD_Year\"] >= 2017].groupby(\"Order Number\").agg(\"count\")[\"Order Date\"])\n",
    "\n",
    "Compliment of Recommend Sku if Have Sku - Need to account for disco skus\n",
    "\n",
    "YMM Detials/preferences\n",
    "- Brands\n",
    "- Parttype\n",
    "- series\n",
    "\n",
    "Sku Details\n",
    "- Brand\n",
    "- Internal Sku\n",
    "- Sku\n",
    "- Title\n",
    "- Price\n",
    "- Part type\n",
    "- Series Associated with\n",
    "- Estimated shipping time\n",
    "- Supplier\n",
    "- Image (in app presenting)\n",
    "- Type & Reason for refund Rate and most common reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Issue Rate\n",
    "from numpy import inf\n",
    "\n",
    "NoIssueSku = CompiledSales[CompiledSales[\"Type\"].isnull()].groupby(\"SKU\").agg(\"count\")[\"Order Date\"].reset_index()\n",
    "IssueSku = CompiledSales[~CompiledSales[\"Type\"].isnull()].groupby(\"SKU\").agg(\"count\")[\"Order Date\"].reset_index()\n",
    "NoIssueSku.columns = [\"internal_sku\", \"NoIssue\"]\n",
    "IssueSku.columns = [\"internal_sku\", \"Issue\"]\n",
    "\n",
    "IssueRate = NoIssueSku.merge(IssueSku, on = \"internal_sku\", how = 'outer')\n",
    "IssueRate[\"Issue\"] = IssueRate[\"Issue\"].fillna(0)\n",
    "IssueRate[\"NoIssue\"]= IssueRate[\"NoIssue\"].fillna(0)\n",
    "\n",
    "IssueRate[\"rate\"] = IssueRate[\"Issue\"]/IssueRate[\"NoIssue\"]\n",
    "IssueRate[\"rate\"][IssueRate[\"rate\"] == inf] = 1\n",
    "IssueRate[\"rate\"] = IssueRate[\"rate\"]*100\n",
    "\n",
    "IssueReasonsSku = CompiledSales[~CompiledSales[\"Type\"].isnull()].groupby([\"SKU\", \"Reason\"]).agg(\"count\")[\"Order Date\"].reset_index()\n",
    "IssueReasonsSku.columns = [\"internal_sku\", \"Reason\", \"count\"]\n",
    "\n",
    "\n",
    "def SkuIssueProp(IS):\n",
    "\n",
    "    SkuIR = int(IssueRate[IssueRate[\"internal_sku\"] == IS][\"rate\"])\n",
    "    if SkuIR != 0:\n",
    "\n",
    "        ReasonOutput = IssueReasonsSku[IssueReasonsSku[\"internal_sku\"] == IS].sort_values(\"count\", ascending = False)\n",
    "        ReasonOutput[\"ReasonRate\"] = (ReasonOutput[\"count\"]/sum(ReasonOutput[\"count\"]))*100\n",
    "        IRs = ReasonOutput[[\"Reason\", \"ReasonRate\"]]\n",
    "    else: \n",
    "        IRs = pd.DataFrame(columns = [\"Reason\", \"ReasonRate\"])\n",
    "    return(SkuIR, IRs)\n",
    "\n",
    "output = SkuIssueProp(IS = \"SpyderAutomotive-5084514\")\n",
    "output[1]\n",
    "output[0]\n",
    "\n",
    "IssueReasonsSku.sort_values(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find compliment skus\n",
    "\n",
    "CompiledSales[CompiledSales[\"SKU\"] == \"WeatherTech-444401\"][['Year', 'Make', 'Model']].groupby(['Year', 'Make', 'Model']).agg(\"count\").reset_index()\n",
    "\n",
    "Sku = \"HuskyLiners-18361\"\n",
    "Y = \"2018\"\n",
    "Mk = \"FORD\"\n",
    "Mo = \"F-150\"\n",
    "\n",
    "(CompiledSales[(CompiledSales[\"SKU\"] != Sku) &\n",
    "              (CompiledSales[\"Year\"] == Y) &\n",
    "              (CompiledSales[\"Make\"] == Mk) &\n",
    "              (CompiledSales[\"Model\"] == Mo)]\n",
    "              .groupby(\"SKU\")\n",
    "              .agg(\"count\")\n",
    "              .sort_values(\"Order Date\", ascending = False)\n",
    "              .reset_index()[[\"SKU\", \"Order Date\"]])\n",
    "\n",
    "CompiledSales.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommneded Sku per YMM\n",
    "import math\n",
    "\n",
    "YMMmonRef = CompiledSales.groupby(['Year', 'Make', 'Model', \"OD_MonthLab\"]).agg(\"count\").reset_index()[['Year', 'Make', 'Model', \"OD_MonthLab\"]]\n",
    "YMMRef = CompiledSales.groupby(['Year', 'Make', 'Model']).agg(\"count\").reset_index()[['Year', 'Make', 'Model']]\n",
    "MMRef = CompiledSales.groupby(['Make', 'Model']).agg(\"count\").reset_index()[['Make', 'Model']]\n",
    "MRef = CompiledSales.groupby([ 'Make']).agg(\"count\").reset_index()[['Make']]\n",
    "\n",
    "\n",
    "#Desired Brand per Ref\n",
    "for m in range(len(MRef)):\n",
    "    make = MRef.iloc[m,0]\n",
    "    MRef.loc[m,\"Brand\"] = (CompiledSales[CompiledSales[\"Make\"] == make]\n",
    "     .groupby(\"Brands\")\n",
    "     .agg(\"count\")\n",
    "     .sort_values(\"Order Date\", ascending = False)\n",
    "     .reset_index()[[\"Brands\", \"Order Date\"]]\n",
    "     .iloc[0,0])\n",
    "    \n",
    "for m in range(len(MMRef)):\n",
    "    make = MMRef.iloc[m,0]\n",
    "    model = MMRef.iloc[m,1]  \n",
    "\n",
    "    subset = CompiledSales[(CompiledSales[\"Model\"] == model) & (CompiledSales[\"Make\"] == make) ]\n",
    "    if list(pd.isnull(subset.Brands))[0] == Fase:\n",
    "        MMRef.loc[m,\"Brand\"] = (subset\n",
    "         .groupby(\"Brands\")\n",
    "         .agg(\"count\")\n",
    "         .sort_values(\"Order Date\", ascending = False)\n",
    "         .reset_index()[[\"Brands\", \"Order Date\"]]\n",
    "         .iloc[0,0])\n",
    "    else:\n",
    "        MMRef.loc[m,\"Brand\"] = \"\"\n",
    "\n",
    "\n",
    "for m in range(len(YMMRef)):\n",
    "    year = YMMRef.iloc[m,0]\n",
    "    make = YMMRef.iloc[m,1]\n",
    "    model = YMMRef.iloc[m,2]\n",
    "\n",
    "    subset = CompiledSales[(CompiledSales[\"Year\"] == year) & (CompiledSales[\"Make\"] == make) & (CompiledSales[\"Model\"] == model)]\n",
    "    if list(pd.isnull(subset.Brands))[0] == False:\n",
    "        YMMRef.loc[m,\"Brand\"] = (subset\n",
    "         .groupby(\"Brands\")\n",
    "         .agg(\"count\")\n",
    "         .sort_values(\"Order Date\", ascending = False)\n",
    "         .reset_index()[[\"Brands\", \"Order Date\"]]\n",
    "         .iloc[0,0])\n",
    "    else:\n",
    "        YMMRef.loc[m,\"Brand\"] = \"\"\n",
    "\n",
    "        \n",
    "        \n",
    "for m in range(len(YMMRef)):\n",
    "    year = YMMRef.iloc[m,0]\n",
    "    make = YMMRef.iloc[m,1]\n",
    "    model = YMMRef.iloc[m,2]\n",
    "\n",
    "    print(year, make, model)\n",
    "    subset = CompiledSales[(CompiledSales[\"Year\"] == year) & (CompiledSales[\"Make\"] == make) & (CompiledSales[\"Model\"] == model)]\n",
    "    if list(pd.isnull(subset.Brands))[0] == False:\n",
    "        SkuCount = (subset\n",
    "         .groupby(\"SKU\")\n",
    "         .agg(\"count\")\n",
    "         .sort_values(\"Order Date\", ascending = False)\n",
    "         .reset_index()[[\"SKU\", \"Order Date\"]])\n",
    "        \n",
    "        if len(SkuCount) >5:\n",
    "            Max = 5\n",
    "        else:\n",
    "            Max = len(SkuCount)\n",
    "            \n",
    "        for s in range(0, Max):\n",
    "            Col = \"Sku_\"+ str(s)\n",
    "            YMMRef.loc[m,Col] = SkuCount.iloc[s,0]\n",
    "            \n",
    "for m in range(len(YMMmonRef)):\n",
    "    year = YMMmonRef.iloc[m,0]\n",
    "    make = YMMmonRef.iloc[m,1]\n",
    "    model = YMMmonRef.iloc[m,2]\n",
    "    month = YMMmonRef.iloc[m,3]\n",
    "\n",
    "    print(year, make, model)\n",
    "    subset = (CompiledSales[(CompiledSales[\"Year\"] == year) & \n",
    "                            (CompiledSales[\"Make\"] == make) &\n",
    "                            (CompiledSales[\"OD_MonthLab\"] == month) & \n",
    "                            (CompiledSales[\"Model\"] == model)])\n",
    "    if list(pd.isnull(subset.Brands))[0] == False:\n",
    "        SkuCount = (subset\n",
    "         .groupby(\"SKU\")\n",
    "         .agg(\"count\")\n",
    "         .sort_values(\"Order Date\", ascending = False)\n",
    "         .reset_index()[[\"SKU\", \"Order Date\"]])\n",
    "        \n",
    "        if len(SkuCount) >2:\n",
    "            Max = 2\n",
    "        else:\n",
    "            Max = len(SkuCount)\n",
    "            \n",
    "        for s in range(0, Max):\n",
    "            Col = \"Sku_\"+ str(s)\n",
    "            YMMmonRef.loc[m,Col] = SkuCount.iloc[s,0]\n",
    "            \n",
    "MRef                        \n",
    "MMRef[MMRef[\"Make\"] == \"FORD\"]\n",
    "YMMRef[(YMMRef[\"Year\"] == \"1079\") & (YMMRef[\"Make\"] == \"FORD\") & (YMMRef[\"Model\"] == \"MUSTANG\")]\n",
    "YMMRef[(YMMRef[\"Make\"] == \"FORD\") & (YMMRef[\"Model\"] == \"MUSTANG\")]\n",
    "\n",
    "YMMmonRef[(YMMmonRef[\"Make\"] == \"DODGE\") & (YMMmonRef[\"Model\"] == \"CHALLENGER\")]\n",
    "\n",
    "\n",
    "CompiledSales.columns= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompiledSales.columns\n",
    "\n",
    "CusYMMref = (CompiledSales.groupby(['Year', 'Make', 'Model', \"Email\"]).agg(\"count\").reset_index()\n",
    "    [['Year', 'Make', 'Model', \"Email\"]])\n",
    "\n",
    "\n",
    "MultiCusRef = CusYMMref.groupby(['Year', 'Make', 'Model']).agg(\"count\").reset_index()\n",
    "MultiCusRef = MultiCusRef[MultiCusRef[\"Email\"]>1]\n",
    "\n",
    "SpecYMMcus = (CompiledSales[#(CompiledSales[\"Year\"] == \"2019\") & \n",
    "               (CompiledSales[\"Make\"] == \"FORD\") & \n",
    "               (CompiledSales[\"Model\"] == \"MUSTANG\")]\n",
    "                .reset_index()[[\"Email\", \"SKU\"]])\n",
    "\n",
    "skulist = list(SpecYMMcus.SKU.unique())\n",
    "skulist.insert(0, 'Email')\n",
    "\n",
    "PartMatrix = pd.DataFrame(columns = skulist)\n",
    "PartMatrix[\"Email\"] = list(SpecYMMcus.Email.unique())\n",
    "PartMatrix = PartMatrix.fillna(0)\n",
    "PartMatrix.index = PartMatrix[\"Email\"]\n",
    "\n",
    "for d in range(len(SpecYMMcus)):\n",
    "    Email = SpecYMMcus.iloc[d, 0]\n",
    "    SKU = SpecYMMcus.iloc[d, 1]\n",
    "\n",
    "    PartMatrix.loc[Email,SKU ] = PartMatrix.loc[Email,SKU ]  + 1\n",
    "\n",
    "pd.DataFrame(PartMatrix.loc[\"tigoy272@gmail.com\"])\n",
    "\n",
    "\n",
    "(CompiledSales.groupby(['Year', 'Make', 'Model', \"Email\"]).agg(\"count\").reset_index()\n",
    "    [['Year', 'Make', 'Model', \"Email\", \"Order Date\"]]\n",
    "    .sort_values(\"Order Date\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify if any brands or skus mismatching between SubSheets and Mainsheets\n",
    "SS_sku = set(CompiledSubSheet[\"internal_sku\"].unique())\n",
    "MS_sku = set(CompiledMainSheet[\"internal_sku\"].unique())\n",
    "\n",
    "len(MS_sku) - len(SS_sku)\n",
    "\n",
    "#difference\n",
    "len(MS_sku - SS_sku)\n",
    "len(SS_sku - MS_sku)\n",
    "\n",
    "MissMatch = pd.DataFrame({\"sku\": list(SS_sku - MS_sku)})\n",
    "MissMatch = pd.DataFrame({\"sku\": list(MS_sku - SS_sku)})\n",
    "\n",
    "#symetric Difference\n",
    "len(SS_sku ^ MS_sku)\n",
    "\n",
    "\n",
    "MissMatch.to_csv (r'//192.168.2.32/Group/Data Team/Abul/4. Temp Folder/MissMatch.csv', index = None, header=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangent Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile all column names in subsheet and create refrence (Created at JT's Request)\n",
    "#This is a seperate analysis from the recommendation engin\n",
    "    \n",
    "AllBrandFolderPath = \"//192.168.2.32/GoogleDrive/Completed Magento Uploads (v 1.0)\"\n",
    "AllBrandFolders = os.listdir(AllBrandFolderPath)\n",
    "\n",
    "SSfile_ss_clean = pd.DataFrame(columns=[\"pd\", \"value\"])\n",
    "\n",
    "for b in range(len(AllBrandFolders)):\n",
    "    Brand = AllBrandFolders[b]\n",
    "    print((len(AllBrandFolders)-b), Brand)\n",
    "    BrandPath= str(AllBrandFolderPath+\"/\"+Brand)\n",
    "    BrandSSpath = BrandPath+\"/sub--*.csv\"\n",
    "    filecount = len(gl.glob(BrandSSpath))\n",
    "    if filecount >= 1:\n",
    "        for f in range(filecount):\n",
    "            SSFile = gl.glob(BrandSSpath)[f]\n",
    "            SSfile = pd.read_csv(SSFile, encoding='mac_roman')\n",
    "            BrandSS = list(map(str.strip, SSfile.columns))\n",
    "            SSfile.columns = BrandSS\n",
    "            \n",
    "            if (\"start_year\" in BrandSS) == True:\n",
    "                SSfile_ss = SSfile.drop(columns=[\"internal_sku\",\"start_year\", \"end_year\",\"make\",\"model\"])\n",
    "            else:\n",
    "                SSfile_ss = SSfile.drop(columns=[\"internal_sku\",\"year\",\"make\",\"model\"])\n",
    "\n",
    "        for c in range(len(SSfile_ss.columns)):\n",
    "            ColValues = pd.DataFrame({\"pd\":list(SSfile_ss.columns)[c], \"value\":SSfile_ss[list(SSfile_ss.columns)[c]].unique()})\n",
    "            SSfile_ss_clean = pd.concat([SSfile_ss_clean,ColValues], axis=0, ignore_index=True, sort=False)\n",
    "            SSfile_ss_clean = SSfile_ss_clean[SSfile_ss_clean[\"pd\"]!=\"special_notes_pd\"]\n",
    "            \n",
    "A = SSfile_ss_clean[~SSfile_ss_clean[\"value\"].isna()]\n",
    "B = A[\"pd\"] + \"@\" + A[\"value\"].astype(str)\n",
    "C = pd.DataFrame({\"comb\":B.unique()})\n",
    "D = C[\"comb\"].str.split(\"@\", n = 1, expand = True) \n",
    "D.columns = [\"pd\", \"value\"]\n",
    "SSfile_pd = D\n",
    "\n",
    "SSfile_pd = Groupby and then concat\n",
    "\n",
    "SSfile_pd.to_csv (r'//192.168.2.32/Group/Data Team/Abul/4. Temp Folder/SSfile_pd.csv', index = None, header=True) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
